{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc0039-37c5-4242-bdff-c8ca0a7bf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!omz_downloader -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493dfc2-2c4b-4ece-96dd-7f3a77ebad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!omz_downloader --print_all  # 다운로드 가능한 모델들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde777ae-312f-4325-9ac4-ecfe6ff1d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "!omz_downloader --name face-detection-adas-0001 --precision FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c7a27-0653-4e47-a70e-6ba19d9d4de3",
   "metadata": {},
   "source": [
    "## 기초 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e3fb26-30b3-48b9-8b79-679629202d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6996bd8-c341-42d2-a31a-684e948a6c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer shape: [1,3,384,672]\n",
      "Output layer shape: [1,1,200,7]\n"
     ]
    }
   ],
   "source": [
    "core = ov.Core()\n",
    "\n",
    "model = core.read_model(model=\"models/face-detection-adas-0001.xml\")\n",
    "face_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "face_input_layer = face_model.input(0)\n",
    "face_output_layer = face_model.output(0)\n",
    "print(\"Input layer shape:\", face_input_layer.shape)\n",
    "print(\"Output layer shape:\", face_output_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41beb82f-8829-4c76-9557-64119dff3ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"data/adults.jpg\")\n",
    "#print(image.shape)\n",
    "\n",
    "resized_image = cv2.resize(src=image, dsize=(672,384))\n",
    "transposed_image = resized_image.transpose(2,0,1)  # (384,672,3) => (3,384,672)\n",
    "input_image = np.expand_dims(transposed_image, 0)  # 차원확장. (1,3,384,672)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6435a8ba-b21e-4441-b0bc-f1e198ef2002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.         1.         1.         ... 0.1503618  0.6402889\n",
      "    0.29027292]\n",
      "   [0.         1.         1.         ... 0.24026465 0.3971492\n",
      "    0.37072134]\n",
      "   [0.         1.         1.         ... 0.25206834 0.7983894\n",
      "    0.38078588]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "face_output = face_model([input_image])[face_output_layer] # input_frame을 face_output_layer형태로 돌려주겠다.\n",
    "print(face_output)  # 출력형태 : (image ID, label, conf, x_min, y_min, x_max, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073afe4-738a-48b9-8941-1ce8e6eb1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 넘파이 배열 자세히 보기\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)  # 넘파이 배열 자세히 예쁘게 보기\n",
    "print(face_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf55c5-d2c9-474b-ae31-41322f496625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이 배열 자세히 보기를 취소하고 원래 설정값으로 보기\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=75, nanstr='nan', precision=8, suppress=False, threshold=1000, formatter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e958df8d-e8df-4233-a654-c2aff30e2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawBoundingBoxes(output, image, conf):\n",
    "    canvas = image.copy()                             # 원본 이미지를 수정하는 대신 복사합니다\n",
    "    h,w,_ = canvas.shape                      # 이미지의 형태 : (높이, 폭, 채널)\n",
    "    \n",
    "    predictions = output[0][0]                         # 하위 집합 데이터 프레임\n",
    "    confidence = predictions[:,2]                       # conf 값 가져오기 [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "  \n",
    "    top_predictions = predictions[(confidence>conf)]         # 임계값보다 큰 conf 값을 가진 예측만 선택\n",
    " \n",
    "    for detection in top_predictions:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # 상자 위치 결정 \n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")   # xmin, ymin, xmax, ymax에 상자 위치 값 지정(자료형을 int로 변경)\n",
    "   \n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)       # 사각형 만들기\n",
    "    \n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99fc1cd5-e62b-4af1-b4be-6a171a08266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = DrawBoundingBoxes(face_output, image, conf=0.5)\n",
    "cv2.imshow(\"Face\", canvas) # 이미지 보기\n",
    "\n",
    "cv2.waitKey(0)           # 키입력 대기(ms 단위). 0이면 무한대기. waitKey()함수가 없다면 imshow()함수는 순식간에 지나가서 볼 수가 없음.\n",
    "cv2.destroyAllWindows()  # 열린 모든 창 닫기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f682aa-2de0-4e8c-9f7b-d6e29f46feeb",
   "metadata": {},
   "source": [
    "### 배경화면에 이미지 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cb0e974-cd53-4162-b8cb-1d7c43d43841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddBackground(frame, bg):\n",
    "\n",
    "    frame_h, frame_w = frame.shape[0], frame.shape[1]\n",
    "    new_h = 500\n",
    "    new_w = int((new_h/frame_h)*frame_w)\n",
    "    frame_resize = cv2.resize(frame, (new_w, new_h))\n",
    "\n",
    "    xmax = bg.shape[1] - 270\n",
    "    ymax = bg.shape[0] - 175\n",
    "    xmin = xmax - new_w\n",
    "    ymin = ymax - new_h\n",
    "\n",
    "    bg[ymin:ymax, xmin:xmax] = frame_resize\n",
    "\n",
    "    return bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "157a8d66-8a2a-467e-adc6-c9d7379a65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = \"data/background.jpg\"  #사용할 배경화면 경로\n",
    "canvas = DrawBoundingBoxes(face_output, image, conf=0.5)  \n",
    "bg = cv2.imread(background)\n",
    "\n",
    "deployment = AddBackground(canvas, bg)\n",
    "cv2.imshow(\"Deployment\", deployment)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2573438e-f957-4a73-a80f-beb1650d3d07",
   "metadata": {},
   "source": [
    "## 배포(Gradio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b5a491d-3275-4a90-a50d-6926ba184fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73a9f0ff-4731-4537-9841-06696993b8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPU', 'GPU']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core = ov.Core()\n",
    "options = core.available_devices\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd3b9d1a-e34f-472d-958a-f457abb1d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = core.read_model(model=\"models/face-detection-adas-0001.xml\")\n",
    "face_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "face_input_layer = face_model.input(0)\n",
    "face_output_layer = face_model.output(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c42ea291-9c65-4ed7-ad70-06e78e028b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로 입력된 이미지 데이터 전처리\n",
    "def preprocess(new_image):\n",
    "    resized_image = cv2.resize(src=new_image, dsize=(672, 384)) \n",
    "    transposed_image = resized_image.transpose(2, 0, 1)\n",
    "    input_image = np.expand_dims(transposed_image, 0)\n",
    "    \n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae2dc708-75f9-4834-b139-c4002a5c43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 추론 결과 후처리: 시각화(인식된 얼굴 주변에 박스 그리기)\n",
    "def DrawBoundingBoxes(new_image, face_output, conf):\n",
    "    canvas = new_image.copy()\n",
    "    h,w,_ = canvas.shape \n",
    "    predictions = face_output[0][0]            # 하위 집합 데이터 프레임\n",
    "    confidence = predictions[:,2]              # conf 값 가져오기 [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    top_predictions = predictions[(confidence>conf)]         # 임계값보다 큰 conf 값을 가진 예측만 선택\n",
    "    for detection in top_predictions:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # 상자 위치 결정\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")  # xmin, ymin, xmax, ymax에 상자 위치 값 지정\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)       # 사각형 만들기\n",
    "        \n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d0dbb18-3302-46da-b558-c002b5b0a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 추론\n",
    "def predict_image(new_image):\n",
    "    input_image = preprocess(new_image)  # Preprocess the image\n",
    "    face_output = face_model([input_image])[face_output_layer]  # Perform inference  \n",
    "    canvas = DrawBoundingBoxes(new_image, face_output, conf=0.5)\n",
    "    \n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "045f6154-b516-484b-95c8-de2619618f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=predict_image,\n",
    "             inputs=gr.Image(type=\"numpy\"),  # 넘파이 배열 사용\n",
    "             outputs=gr.Image(type=\"numpy\"), # 넘파이 배열 처럼 출력\n",
    "             examples=[\"data/test.jpg\"]).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58874940-2ba9-4d9b-a510-3d2e49ed24fd",
   "metadata": {},
   "source": [
    "## 영상 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea21b424-63e0-44a9-94de-8e3cedbda647",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)   # 웹캠의 경우는 0, 동영상의 경우는 경로 적기\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    face_detection = predict_image(frame)\n",
    "    cv2.imshow('Press Spacebar to Exit', face_detection)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8bfdb03-c9eb-4693-8b70-51591904e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배경 화면에 영상 넣기\n",
    "camera = cv2.VideoCapture(0)   # 웹캠의 경우는 0, 동영상의 경우는 경로 적기\n",
    "background = \"data/background.jpg\"  #사용할 배경화면 경로\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    face_detection = predict_image(frame)\n",
    "    bg = cv2.imread(background)\n",
    "\n",
    "    deployment = AddBackground(face_detection, bg)\n",
    "    cv2.imshow('Press Spacebar to Exit', deployment)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eeba82-a1ee-464c-97cd-88c619bef8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
